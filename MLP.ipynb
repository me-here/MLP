{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal 1: Create perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, W, b):\n",
    "    '''\n",
    "    Input: weights W, biases b, input activations x\n",
    "    Output: Single hypothesis\n",
    "    '''\n",
    "    z = np.sum(W.T * x) + b\n",
    "    return sigmoid(z)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def deriv_sigmoid(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887711125213482"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = np.array([0.3, 0.1, 0.7, 8])\n",
    "weights = np.random.rand(activations.shape[0])\n",
    "bias = 1\n",
    "\n",
    "perceptron(activations, weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal 2: Get, Clean, & Normalize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  OverallQual  OverallCond  TotalBsmtSF  FullBath  HalfBath  \\\n",
      "0     8450            7            5          856         2         1   \n",
      "1     9600            6            8         1262         2         0   \n",
      "2    11250            7            5          920         2         1   \n",
      "3     9550            7            5          756         1         0   \n",
      "4    14260            8            5         1145         2         1   \n",
      "\n",
      "   BedroomAbvGr  TotRmsAbvGrd  Fireplaces  GarageArea  AboveMedianPrice  \n",
      "0             3             8           0         548                 1  \n",
      "1             3             6           1         460                 1  \n",
      "2             3             6           1         608                 1  \n",
      "3             3             7           1         642                 0  \n",
      "4             4             9           1         836                 1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"housepricedata.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8450     7     5 ...     8     0   548]\n",
      " [ 9600     6     8 ...     6     1   460]\n",
      " [11250     7     5 ...     6     1   608]\n",
      " ...\n",
      " [ 9042     7     9 ...     9     2   252]\n",
      " [ 9717     5     6 ...     5     0   240]\n",
      " [ 9937     5     6 ...     6     0   276]]\n"
     ]
    }
   ],
   "source": [
    "houses = data.values # DataFrame --> Array\n",
    "x = houses[:, :-1] # Input Activations\n",
    "y = houses[:, -1] # Output labels (0 or 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x = MinMaxScaler().fit(x).transform(x) # features between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valtest, Y_train, Y_valtest = train_test_split(x, y, test_size=0.3) # 70% Train\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_valtest, Y_valtest, test_size=0.5) # 15% to test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1022, 10)\n",
      "(219, 10)\n",
      "(219, 10)\n",
      "(1460, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal 3: Forward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(0)\n",
    "def forwardProp(activations, weights, biases, zArr, numLayers):\n",
    "    '''\n",
    "    Vectorized Implementation\n",
    "    Input: First Layer activations, weights, biases, number of layers\n",
    "    Output: Last layer\n",
    "    '''\n",
    "    # Layer i\n",
    "    for i in range(numLayers-1):\n",
    "        z = np.dot(weights[i], activations[i]) + biases[i]\n",
    "        zArr.append(z)\n",
    "        activations.append(sigmoid(z))\n",
    "\n",
    "params = {\n",
    "    \"weights\": [\n",
    "    np.random.randn(X_train.shape[0], X_train.shape[1]) * np.sqrt(2/X_train.shape[0]), # l1\n",
    "    np.random.randn(1, X_train.shape[0]) * np.sqrt(2/X_train.shape[0])  # l2\n",
    "    ],\n",
    "    \n",
    "    \"biases\": np.ones(numLayers-1),    \n",
    "    \n",
    "    \"numLayers\": 3 \n",
    "}\n",
    "\n",
    "numLayers = 3\n",
    "zArr = []\n",
    "activations = [X_train.T]\n",
    "weights = [\n",
    "    np.random.randn(X_train.shape[0], X_train.shape[1]) * np.sqrt(2/X_train.shape[0]), # l1\n",
    "    np.random.randn(1, X_train.shape[0]) * np.sqrt(2/X_train.shape[0])  # l2\n",
    "          ]\n",
    "biases = np.ones(numLayers-1) # bias in each layer except output\n",
    "\n",
    "forwardProp(activations, weights, biases, zArr, numLayers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173776.4706329683\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def backwardProp(activations, weights, biases, numLayers, actual, zArr, weightDecay, learning_rate):\n",
    "    # Compute Cost\n",
    "    cost = np.mean(1/2 * np.linalg.norm(activations[-1]-actual) ** 2)\n",
    "    for layer in range(numLayers - 1):\n",
    "        for i in range(activations[layer].shape[0]):\n",
    "            for j in range(activations[layer+1].shape[0]):\n",
    "                cost += weights[layer][j][i] ** 2\n",
    "    cost *= weightDecay / 2\n",
    "    print(cost)\n",
    "    \n",
    "    # Output layer delta\n",
    "    deltas = {}\n",
    "    delta_nL = np.multiply(-(actual - activations[-1]), deriv_sigmoid(zArr[-1]))\n",
    "    deltas[2] = delta_nL\n",
    "    \n",
    "    # Go through hidden layers (l2 --> index 1)\n",
    "    for l in range(numLayers-2, 0, -1): \n",
    "        deltas[l] = np.dot(weights[l].T, deltas[l+1]) * deriv_sigmoid(zArr[l])\n",
    "        deriv_W = np.dot(deltas[l+1], activations[l].T)\n",
    "        deriv_b = deltas[l+1]\n",
    "        \n",
    "        print(deriv_W)\n",
    "        weights[l] = weights[l] - learning_rate * deriv_W\n",
    "        # todo: update biases\n",
    "    \n",
    "weightDecay = 0.5\n",
    "learning_rate = 0.001\n",
    "backwardProp(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihir\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n",
      "173776.4706329683\n"
     ]
    }
   ],
   "source": [
    "def runNetwork(activations, weights, biases, numLayers, actual, zArr, weightDecay, learning_rate):\n",
    "    epochs = 10\n",
    "    for x in range(epochs):\n",
    "        forwardProp(activations, weights, biases, zArr, numLayers)\n",
    "        backwardProp(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)\n",
    "    \n",
    "runNetwork(activations, weights, biases, numLayers, Y_train, zArr, weightDecay, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.04645748, -0.11420034,  0.02332669, ..., -0.0530145 ,\n",
      "        -0.01270414, -0.06781076],\n",
      "       [ 0.03650687, -0.00169416,  0.0139566 , ..., -0.01795821,\n",
      "        -0.03512879,  0.06931611],\n",
      "       [-0.04107713, -0.03468755, -0.01679333, ...,  0.02514496,\n",
      "         0.06852584,  0.00804795],\n",
      "       ...,\n",
      "       [ 0.04323556, -0.07361189,  0.005151  , ...,  0.03093557,\n",
      "        -0.00913286, -0.00805881],\n",
      "       [-0.01044397, -0.01612829, -0.07758249, ...,  0.02867128,\n",
      "         0.05306512,  0.01180311],\n",
      "       [ 0.08342361, -0.02342514, -0.00940452, ..., -0.00341371,\n",
      "         0.05061867, -0.03601588]]), array([[-25.52077447, -26.07231193, -26.00936457, ..., -25.89717348,\n",
      "        -25.99631162, -25.81178739]])]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "1. http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/\n",
    "2. https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
